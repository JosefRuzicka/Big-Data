{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Taken from https://machinelearningmastery.com/statistical-imputation-for-missing-values-in-machine-learning/ for my Big Data class.\n",
        "\n",
        "# Statistical Imputation for Missing Values in Machine Learning\n",
        "\n",
        "Datasets may have missing values, and this can cause problems for many machine learning algorithms.\n",
        "\n",
        "As such, it is good practice to identify and replace missing values for each column in your input data prior to modeling your prediction task. This is called missing data imputation, or imputing for short.\n",
        "\n",
        "A popular approach for data imputation is to calculate a statistical value for each column (such as a mean) and replace all missing values for that column with the statistic. It is a popular approach because the statistic is easy to calculate using the training dataset and because it often results in good performance.\n",
        "\n",
        "In this tutorial, you will discover how to use statistical imputation strategies for missing data in machine learning.\n",
        "\n",
        "After completing this tutorial, you will know:\n",
        "\n",
        "* Missing values must be marked with NaN values and can be replaced with statistical measures to calculate the column of values.\n",
        "* How to load a CSV value with missing values and mark the missing values with NaN values and report the number and percentage of missing values for each column.\n",
        "* How to impute missing values with statistics as a data preparation method when evaluating models and when fitting a final model to make predictions on new data.\n",
        "\n",
        "**Kick-start your project** with my new book Data Preparation for Machine Learning, including step-by-step tutorials and the Python source code files for all examples.\n",
        "\n",
        "Let’s get started.\n",
        "\n",
        "Updated Jun/2020: Changed the column used for prediction in examples.\n",
        "\n",
        "## Tutorial Overview\n",
        "This tutorial is divided into three parts; they are:\n",
        "\n",
        "1. Statistical Imputation\n",
        "2. Horse Colic Dataset\n",
        "3. Statistical Imputation With SimpleImputer\n",
        "  1. SimpleImputer Data Transform\n",
        "  2. SimpleImputer and Model Evaluation\n",
        "  3. Comparing Different Imputed Statistics\n",
        "  4. SimpleImputer Transform When Making a Prediction\n",
        "\n",
        "## Statistical Imputation\n",
        "A dataset may have missing values.\n",
        "\n",
        "These are rows of data where one or more values or columns in that row are not present. The values may be missing completely or they may be marked with a special character or value, such as a question mark “?”.\n",
        "\n",
        "> These values can be expressed in many ways. I’ve seen them show up as nothing at all […], an empty string […], the explicit string NULL or undefined or N/A or NaN, and the number 0, among others. No matter how they appear in your dataset, knowing what to expect and checking to make sure the data matches that expectation will reduce problems as you start to use the data.\n",
        "\n",
        "— Page 10, Bad Data Handbook, 2012.\n",
        "\n",
        "Values could be missing for many reasons, often specific to the problem domain, and might include reasons such as corrupt measurements or data unavailability.\n",
        "\n",
        "> They may occur for a number of reasons, such as malfunctioning measurement equipment, changes in experimental design during data collection, and collation of several similar but not identical datasets.\n",
        "\n",
        "— Page 63, Data Mining: Practical Machine Learning Tools and Techniques, 2016.\n",
        "\n",
        "Most machine learning algorithms require numeric input values, and a value to be present for each row and column in a dataset. As such, missing values can cause problems for machine learning algorithms.\n",
        "\n",
        "As such, it is common to identify missing values in a dataset and replace them with a numeric value. This is called data imputing, or missing data imputation.\n",
        "\n",
        "A simple and popular approach to data imputation involves using statistical methods to estimate a value for a column from those values that are present, then replace all missing values in the column with the calculated statistic.\n",
        "\n",
        "It is simple because statistics are fast to calculate and it is popular because it often proves very effective.\n",
        "\n",
        "Common statistics calculated include:\n",
        "\n",
        "* The column mean value.\n",
        "* The column median value.\n",
        "* The column mode value.\n",
        "* A constant value.\n",
        "\n",
        "Now that we are familiar with statistical methods for missing value imputation, let’s take a look at a dataset with missing values.\n",
        "\n",
        "## Horse Colic Dataset\n",
        "The horse colic dataset describes medical characteristics of horses with colic and whether they lived or died.\n",
        "\n",
        "There are 300 rows and 26 input variables with one output variable. It is a binary classification prediction task that involves predicting 1 if the horse lived and 2 if the horse died.\n",
        "\n",
        "There are many fields we could select to predict in this dataset. In this case, we will predict whether the problem was surgical or not (column index 23), making it a binary classification problem.\n",
        "\n",
        "The dataset has numerous missing values for many of the columns where each missing value is marked with a question mark character (“?”).\n",
        "\n",
        "Below provides an example of rows from the dataset with marked missing values."
      ],
      "metadata": {
        "id": "ctskW-j5i7h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2,1,530101,38.50,66,28,3,3,?,2,5,4,4,?,?,?,3,5,45.00,8.40,?,?,2,2,11300,00000,00000,2\n",
        "1,1,534817,39.2,88,20,?,?,4,1,3,4,2,?,?,?,4,2,50,85,2,2,3,2,02208,00000,00000,2\n",
        "2,1,530334,38.30,40,24,1,1,3,1,3,3,1,?,?,?,1,1,33.00,6.70,?,?,1,2,00000,00000,00000,1\n",
        "1,9,5290409,39.10,164,84,4,1,6,2,2,4,4,1,2,5.00,3,?,48.00,7.20,3,5.30,2,1,02208,00000,00000,1\n",
        "..."
      ],
      "metadata": {
        "id": "jxF75F3uj4eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can learn more about the dataset here:\n",
        "\n",
        "* Horse Colic Dataset\n",
        "* Horse Colic Dataset Description\n",
        "\n",
        "No need to download the dataset as we will download it automatically in the worked examples.\n",
        "\n",
        "Marking missing values with a NaN (not a number) value in a loaded dataset using Python is a best practice.\n",
        "\n",
        "We can load the dataset using the read_csv() Pandas function and specify the “na_values” to load values of ‘?‘ as missing, marked with a NaN value.\n",
        "\n"
      ],
      "metadata": {
        "id": "l9D8UqAlj5IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
        "dataframe = read_csv(url, header=None, na_values='?')"
      ],
      "metadata": {
        "id": "6c8OrTHuj951"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once loaded, we can review the loaded data to confirm that “?” values are marked as NaN."
      ],
      "metadata": {
        "id": "M1IEZFY-kAid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# summarize the first few rows\n",
        "print(dataframe.head())"
      ],
      "metadata": {
        "id": "hLwiFiH5kBKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then enumerate each column and report the number of rows with missing values for the column."
      ],
      "metadata": {
        "id": "5lmIr_TBkCxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# summarize the number of rows with missing values for each column\n",
        "for i in range(dataframe.shape[1]):\n",
        "\t# count number of rows with missing values\n",
        "\tn_miss = dataframe[[i]].isnull().sum()\n",
        "\tperc = n_miss / dataframe.shape[0] * 100\n",
        "\tprint('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
      ],
      "metadata": {
        "id": "uygjeDuwkFAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tying this together, the complete example of loading and summarizing the dataset is listed below."
      ],
      "metadata": {
        "id": "JoyZFHaVkG1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the horse colic dataset\n",
        "from pandas import read_csv\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
        "dataframe = read_csv(url, header=None, na_values='?')\n",
        "# summarize the first few rows\n",
        "print(dataframe.head())\n",
        "# summarize the number of rows with missing values for each column\n",
        "for i in range(dataframe.shape[1]):\n",
        "\t# count number of rows with missing values\n",
        "\tn_miss = dataframe[[i]].isnull().sum()\n",
        "\tperc = n_miss / dataframe.shape[0] * 100\n",
        "\tprint('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdLaEVTbkIJ6",
        "outputId": "a8aca50c-9278-4749-8f66-b2aa337e506e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0   1        2     3      4     5    6    7    8    9   ...    18    19  \\\n",
            "0  2.0   1   530101  38.5   66.0  28.0  3.0  3.0  NaN  2.0  ...  45.0   8.4   \n",
            "1  1.0   1   534817  39.2   88.0  20.0  NaN  NaN  4.0  1.0  ...  50.0  85.0   \n",
            "2  2.0   1   530334  38.3   40.0  24.0  1.0  1.0  3.0  1.0  ...  33.0   6.7   \n",
            "3  1.0   9  5290409  39.1  164.0  84.0  4.0  1.0  6.0  2.0  ...  48.0   7.2   \n",
            "4  2.0   1   530255  37.3  104.0  35.0  NaN  NaN  6.0  2.0  ...  74.0   7.4   \n",
            "\n",
            "    20   21   22  23     24  25  26  27  \n",
            "0  NaN  NaN  2.0   2  11300   0   0   2  \n",
            "1  2.0  2.0  3.0   2   2208   0   0   2  \n",
            "2  NaN  NaN  1.0   2      0   0   0   1  \n",
            "3  3.0  5.3  2.0   1   2208   0   0   1  \n",
            "4  NaN  NaN  2.0   2   4300   0   0   2  \n",
            "\n",
            "[5 rows x 28 columns]\n",
            "> 0, Missing: 1 (0.3%)\n",
            "> 1, Missing: 0 (0.0%)\n",
            "> 2, Missing: 0 (0.0%)\n",
            "> 3, Missing: 60 (20.0%)\n",
            "> 4, Missing: 24 (8.0%)\n",
            "> 5, Missing: 58 (19.3%)\n",
            "> 6, Missing: 56 (18.7%)\n",
            "> 7, Missing: 69 (23.0%)\n",
            "> 8, Missing: 47 (15.7%)\n",
            "> 9, Missing: 32 (10.7%)\n",
            "> 10, Missing: 55 (18.3%)\n",
            "> 11, Missing: 44 (14.7%)\n",
            "> 12, Missing: 56 (18.7%)\n",
            "> 13, Missing: 104 (34.7%)\n",
            "> 14, Missing: 106 (35.3%)\n",
            "> 15, Missing: 247 (82.3%)\n",
            "> 16, Missing: 102 (34.0%)\n",
            "> 17, Missing: 118 (39.3%)\n",
            "> 18, Missing: 29 (9.7%)\n",
            "> 19, Missing: 33 (11.0%)\n",
            "> 20, Missing: 165 (55.0%)\n",
            "> 21, Missing: 198 (66.0%)\n",
            "> 22, Missing: 1 (0.3%)\n",
            "> 23, Missing: 0 (0.0%)\n",
            "> 24, Missing: 0 (0.0%)\n",
            "> 25, Missing: 0 (0.0%)\n",
            "> 26, Missing: 0 (0.0%)\n",
            "> 27, Missing: 0 (0.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example first loads the dataset and summarizes the first five rows.\n",
        "\n",
        "We can see that the missing values that were marked with a “?” character have been replaced with NaN values.\n",
        "\n",
        "Next, we can see the list of all columns in the dataset and the number and percentage of missing values.\n",
        "\n",
        "We can see that some columns (e.g. column indexes 1 and 2) have no missing values and other columns (e.g. column indexes 15 and 21) have many or even a majority of missing values.\n",
        "\n",
        "Now that we are familiar with the horse colic dataset that has missing values, let’s look at how we can use statistical imputation.\n",
        "\n",
        "## Statistical Imputation With SimpleImputer\n",
        "The scikit-learn machine learning library provides the SimpleImputer class that supports statistical imputation.\n",
        "\n",
        "In this section, we will explore how to effectively use the SimpleImputer class.\n",
        "\n",
        "### SimpleImputer Data Transform\n",
        "The SimpleImputer is a data transform that is first configured based on the type of statistic to calculate for each column, e.g. mean."
      ],
      "metadata": {
        "id": "sCN2C_hrkKSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# define imputer\n",
        "imputer = SimpleImputer(strategy='mean')"
      ],
      "metadata": {
        "id": "SrL_mawAkja5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then the imputer is fit on a dataset to calculate the statistic for each column."
      ],
      "metadata": {
        "id": "rjXx0_dYkmT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# fit on the dataset\n",
        "imputer.fit(X)"
      ],
      "metadata": {
        "id": "m67eAAhnkneU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit imputer is then applied to a dataset to create a copy of the dataset with all missing values for each column replaced with a statistic value."
      ],
      "metadata": {
        "id": "dstWuPw4kuxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# transform the dataset\n",
        "Xtrans = imputer.transform(X)"
      ],
      "metadata": {
        "id": "FEawQcc7kw2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can demonstrate its usage on the horse colic dataset and confirm it works by summarizing the total number of missing values in the dataset before and after the transform.\n",
        "\n",
        "The complete example is listed below."
      ],
      "metadata": {
        "id": "egACKWs7k9sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical imputation transform for the horse colic dataset\n",
        "from numpy import isnan\n",
        "from pandas import read_csv\n",
        "from sklearn.impute import SimpleImputer\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
        "dataframe = read_csv(url, header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# print total missing\n",
        "print('Missing: %d' % sum(isnan(X).flatten()))\n",
        "# define imputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "# fit on the dataset\n",
        "imputer.fit(X)\n",
        "# transform the dataset\n",
        "Xtrans = imputer.transform(X)\n",
        "# print total missing\n",
        "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFU80Nfhk-8s",
        "outputId": "4e5005e0-309f-4ca5-b505-afa52b84beb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing: 1605\n",
            "Missing: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example first loads the dataset and reports the total number of missing values in the dataset as 1,605.\n",
        "\n",
        "The transform is configured, fit, and performed and the resulting new dataset has no missing values, confirming it was performed as we expected.\n",
        "\n",
        "Each missing value was replaced with the mean value of its column.\n",
        "\n",
        "## SimpleImputer and Model Evaluation\n",
        "It is a good practice to evaluate machine learning models on a dataset using k-fold cross-validation.\n",
        "\n",
        "To correctly apply statistical missing data imputation and avoid data leakage, it is required that the statistics calculated for each column are calculated on the training dataset only, then applied to the train and test sets for each fold in the dataset.\n",
        "\n",
        "> If we are using resampling to select tuning parameter values or to estimate performance, the imputation should be incorporated within the resampling.\n",
        "\n",
        "— Page 42, Applied Predictive Modeling, 2013.\n",
        "\n",
        "This can be achieved by creating a modeling pipeline where the first step is the statistical imputation, then the second step is the model. This can be achieved using the Pipeline class.\n",
        "\n",
        "For example, the Pipeline below uses a SimpleImputer with a ‘mean‘ strategy, followed by a random forest model."
      ],
      "metadata": {
        "id": "EZ7ss67BlDj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# define modeling pipeline\n",
        "model = RandomForestClassifier()\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])"
      ],
      "metadata": {
        "id": "w3b5kkLHljI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can evaluate the mean-imputed dataset and random forest modeling pipeline for the horse colic dataset with repeated 10-fold cross-validation.\n",
        "\n",
        "The complete example is listed below."
      ],
      "metadata": {
        "id": "5UEQ9ZDjlkcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate mean imputation and random forest for the horse colic dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
        "dataframe = read_csv(url, header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# define modeling pipeline\n",
        "model = RandomForestClassifier()\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
        "# define model evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxHTaCPclm5a",
        "outputId": "7a57584f-16af-4749-910a-7eab2955914e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.859 (0.055)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example correctly applies data imputation to each fold of the cross-validation procedure.\n",
        "\n",
        "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
        "\n",
        "The pipeline is evaluated using three repeats of 10-fold cross-validation and reports the mean classification accuracy on the dataset as about 86.3 percent, which is a good score.\n",
        "\n",
        "## Comparing Different Imputed Statistics\n",
        "How do we know that using a ‘mean‘ statistical strategy is good or best for this dataset?\n",
        "\n",
        "The answer is that we don’t and that it was chosen arbitrarily.\n",
        "\n",
        "We can design an experiment to test each statistical strategy and discover what works best for this dataset, comparing the mean, median, mode (most frequent), and constant (0) strategies. The mean accuracy of each approach can then be compared.\n",
        "\n",
        "The complete example is listed below."
      ],
      "metadata": {
        "id": "2Lxg7uGylqlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare statistical imputation strategies for the horse colic dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
        "dataframe = read_csv(url, header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# evaluate each strategy on the dataset\n",
        "results = list()\n",
        "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
        "for s in strategies:\n",
        "\t# create the modeling pipeline\n",
        "\tpipeline = Pipeline(steps=[('i', SimpleImputer(strategy=s)), ('m', RandomForestClassifier())])\n",
        "\t# evaluate the model\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\t# store results\n",
        "\tresults.append(scores)\n",
        "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=strategies, showmeans=True)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "85t6Nvahl-23",
        "outputId": "9bc8123d-77ae-40c9-af01-d6273810bf93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">mean 0.858 (0.062)\n",
            ">median 0.863 (0.057)\n",
            ">most_frequent 0.869 (0.053)\n",
            ">constant 0.878 (0.050)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example evaluates each statistical imputation strategy on the horse colic dataset using repeated cross-validation.\n",
        "\n",
        "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
        "\n",
        "The mean accuracy of each strategy is reported along the way. The results suggest that using a constant value, e.g. 0, results in the best performance of about 88.1 percent, which is an outstanding result.\n",
        "\n",
        "At the end of the run, a box and whisker plot is created for each set of results, allowing the distribution of results to be compared.\n",
        "\n",
        "We can clearly see that the distribution of accuracy scores for the constant strategy is better than the other strategies.\n",
        "\n",
        "## SimpleImputer Transform When Making a Prediction\n",
        "We may wish to create a final modeling pipeline with the constant imputation strategy and random forest algorithm, then make a prediction for new data.\n",
        "\n",
        "This can be achieved by defining the pipeline and fitting it on all available data, then calling the predict() function passing new data in as an argument.\n",
        "\n",
        "Importantly, the row of new data must mark any missing values using the NaN value."
      ],
      "metadata": {
        "id": "i-o0qgvlmBZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "...\n",
        "# define new data\n",
        "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]"
      ],
      "metadata": {
        "id": "XqdYEz8OmLXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The complete example is listed below."
      ],
      "metadata": {
        "id": "4P3JXv6YmNWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# constant imputation strategy and prediction for the hose colic dataset\n",
        "from numpy import nan\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "# load dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
        "dataframe = read_csv(url, header=None, na_values='?')\n",
        "# split into input and output elements\n",
        "data = dataframe.values\n",
        "ix = [i for i in range(data.shape[1]) if i != 23]\n",
        "X, y = data[:, ix], data[:, 23]\n",
        "# create the modeling pipeline\n",
        "pipeline = Pipeline(steps=[('i', SimpleImputer(strategy='constant')), ('m', RandomForestClassifier())])\n",
        "# fit the model\n",
        "pipeline.fit(X, y)\n",
        "# define new data\n",
        "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
        "# make a prediction\n",
        "yhat = pipeline.predict([row])\n",
        "# summarize prediction\n",
        "print('Predicted Class: %d' % yhat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rJca4-pmOSv",
        "outputId": "e6f06d19-b95a-47a3-d0a8-476f90c53b64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the example fits the modeling pipeline on all available data.\n",
        "\n",
        "A new row of data is defined with missing values marked with NaNs and a classification prediction is made.\n",
        "\n",
        "## Further Reading\n",
        "This section provides more resources on the topic if you are looking to go deeper.\n",
        "\n",
        "## Related Tutorials\n",
        "* Results for Standard Classification and Regression Machine Learning Datasets\n",
        "* How to Handle Missing Data with Python\n",
        "\n",
        "## Books\n",
        "* Bad Data Handbook, 2012.\n",
        "* Data Mining: Practical Machine Learning Tools and Techniques, 2016.\n",
        "* Applied Predictive Modeling, 2013.\n",
        "\n",
        "## APIs\n",
        "* Imputation of missing values, scikit-learn Documentation.\n",
        "* sklearn.impute.SimpleImputer API.\n",
        "\n",
        "## Dataset\n",
        "* Horse Colic Dataset\n",
        "* Horse Colic Dataset Description\n",
        "\n",
        "# Summary\n",
        "In this tutorial, you discovered how to use statistical imputation strategies for missing data in machine learning.\n",
        "\n",
        "Specifically, you learned:\n",
        "\n",
        "* Missing values must be marked with NaN values and can be replaced with statistical measures to calculate the column of values.\n",
        "* How to load a CSV value with missing values and mark the missing values with NaN values and report the number and percentage of missing values for each column.\n",
        "* How to impute missing values with statistics as a data preparation method when evaluating models and when fitting a final model to make predictions on new data.\n",
        "\n",
        "#### Do you have any questions?\n",
        "Ask your questions in the comments below and I will do my best to answer.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z0mqqHOVmWLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taken from https://machinelearningmastery.com/statistical-imputation-for-missing-values-in-machine-learning/ for my Big Data class."
      ],
      "metadata": {
        "id": "9oiU1nczm5s2"
      }
    }
  ]
}